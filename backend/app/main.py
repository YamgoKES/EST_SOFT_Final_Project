from fastapi import FastAPI, UploadFile, File, Form
import torch
from PIL import Image
from fastapi.middleware.cors import CORSMiddleware
import os
from dotenv import load_dotenv
import re

#ëª¨ë¸ ë° ì „ì²˜ë¦¬ ì„í¬íŠ¸ë€
from .process_age_gender import YoloTransform, transform, yolo_model_path
from .model_age_gender import model_e_v1, device
from .EA_predictor import EmotionFANPredictor_Attention 
from .openai_helper import build_prompt_v2, ask_chatgpt
from .naver_api import search_naver_items

app = FastAPI()

# CORS í—ˆìš© ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ë˜ëŠ” ["http://localhost:3000"]
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

processor = YoloTransform(
    yolo_model_path=yolo_model_path,
    conf_threshold=0.7,
    transform=transform
)

#ê°ì •ì˜ˆì¸¡
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
EMOTION_MODEL_PATH = os.path.abspath(os.path.join(BASE_DIR, '..', 'trained', 'best_model.pth'))

emotion_predictor=EmotionFANPredictor_Attention(
    model_path=EMOTION_MODEL_PATH,
    device = None,
    face_model_path=yolo_model_path,
    use_face_crop = True
)

@app.post('/predict')
async def predict(file: UploadFile = File(...), feel_mode: str =Form(...)) :
    print(f"ğŸ“¦ ë°›ì€ feel_mode ê°’: {feel_mode}")
    image = Image.open(file.file).convert('RGB')
    input_tensor = processor.detect_best_cropping(image)
    input_tensor = input_tensor.to(device)

    #ë‚˜ì´ ì„±ë³„ ì˜ˆì¸¡
    with torch.no_grad():
        out_put = model_e_v1(input_tensor)
        predicted_age = out_put[:,0].item()
        predicted_gender_idx = torch.argmax(out_put[:,1:3], dim=1).item()
        predicted_gender = 'Male' if predicted_gender_idx==1 else 'Female'
    
    #ê°ì •ë¶„ì„
    emotion_result = emotion_predictor.predict(image)
    emotion=emotion_result['emotion']
    
    # í”„ë¡¬í”„íŠ¸ ìƒì„± (feel_mode í¬í•¨)
    load_dotenv() 
    api_key=os.getenv('OPENAI_API_KEY')
    prompt = build_prompt_v2(emotion, predicted_gender, predicted_age * (60-10) + 10, feel_mode)
    recommendation_text = ask_chatgpt(prompt, api_key=api_key)
    
    #Navershopping api / recommendation
    categories = re.findall(r"<\[(.*?)\]>", recommendation_text)
    
    #ì¶”ì²œ ì¹´í…Œê³ ë¦¬ ( ê° ì¶”ì²œì¹´í…Œê³ ë¦¬ ë³„(3ê°œ) ëœë¤ 5ê°œ ë½‘ì•„ë‚´ê¸°)
    recommendation_items = []
    seen_links = set()

    num_cats = len(categories)
    min_per_cat = 1
    remaining_slots = 5 - (min_per_cat * num_cats)

    # ì¹´í…Œê³ ë¦¬ë³„ë¡œ 3~5ê°œì”© ë¯¸ë¦¬ ë°›ì•„ì˜¤ê¸° (í•œ ë²ˆì— ë§ì´ ìš”ì²­)
    fetch_count_per_cat = 5

    cat_items_map = {}  # ì¹´í…Œê³ ë¦¬ë³„ ë°›ì€ ì•„ì´í…œ ì €ì¥

    for cat in categories:
        items = search_naver_items(cat, display=fetch_count_per_cat)
        cat_items_map[cat] = items or []

    # 1ë‹¨ê³„: ê° ì¹´í…Œê³ ë¦¬ë³„ ìµœì†Œ 1ê°œì”© ì¤‘ë³µ ì—†ì´ ì¶”ê°€
    for cat in categories:
        items = cat_items_map[cat]
        for item in items:
            link = item.get('link')
            if link and link not in seen_links:
                recommendation_items.append(item)
                seen_links.add(link)
                break

    # 2ë‹¨ê³„: ë‚¨ì€ ìŠ¬ë¡¯ ì±„ìš°ê¸° (ì „ì²´ ì¹´í…Œê³ ë¦¬ ì•„ì´í…œ ìˆœíšŒí•˜ë©° ì¤‘ë³µ ì—†ì´ ì¶”ê°€)
    if len(recommendation_items) < 5:
        for cat in categories:
            items = cat_items_map[cat]
            for item in items:
                if len(recommendation_items) >= 5:
                    break
                link = item.get('link')
                if link and link not in seen_links:
                    recommendation_items.append(item)
                    seen_links.add(link)

    # ê²°ê³¼ ìµœëŒ€ 5ê°œ
    recommendation_items = recommendation_items[:5]
    return {
        'age' : int(round(predicted_age * (60-10) +10, 1)), #ì—­ì •ê·œí™”..
        'gender' : predicted_gender ,
        'emotion' : emotion, 
        'recommendationtext': recommendation_text, #summaryë¶€ë¶„
        "recommendationItems": recommendation_items #ì¶”ì²œìƒí’ˆ
    }
        


