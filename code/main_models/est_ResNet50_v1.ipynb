{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e344eabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import 부분\n",
    "import time\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "from functools import partial\n",
    "from torchvision.models import resnet50\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "#정확도 및 mae 임포트\n",
    "from torchmetrics import Accuracy, MeanAbsoluteError\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df961108",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afa61b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 디바이스: cuda\n",
      "CUDA 사용 가능 여부: True\n",
      "현재 CUDA 디바이스 인덱스: 0\n",
      "CUDA 디바이스 이름: NVIDIA GeForce RTX 4060 Ti\n"
     ]
    }
   ],
   "source": [
    "print(\"사용 디바이스:\", device)\n",
    "print(\"CUDA 사용 가능 여부:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"현재 CUDA 디바이스 인덱스:\", torch.cuda.current_device())\n",
    "    print(\"CUDA 디바이스 이름:\", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bebcdccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessing(Dataset) :\n",
    "    \n",
    "    def __init__(self, image_dir, label_dir, categories, transform=None, mode='train') :\n",
    "        \n",
    "        self.datalist = []\n",
    "        self.transform = transform\n",
    "        self.label_map = {cat : idx for idx, cat in enumerate(categories)} #숫자로 변환 ?\n",
    "        self.mode = mode \n",
    "        self.age_min = 10\n",
    "        self.age_max = 60\n",
    "        \n",
    "        for category in categories :\n",
    "            \n",
    "            json_path = os.path.join(label_dir, f'{self.mode}_crop_{category}.json') \n",
    "            img_folder =  os.path.join(image_dir, category)\n",
    "            \n",
    "            with open(json_path, 'r', encoding='utf-8') as f :\n",
    "                label_data = json.load(f)        \n",
    "                \n",
    "            for row in label_data :\n",
    "                filename = row['filename']  # 예: 'abc_crop20.jpg'\n",
    "                \n",
    "                # base_filename은 확장자(.jpg)만 제거한 원본명\n",
    "                base_filename = filename.replace('.jpg', '')  \n",
    "                \n",
    "                # base_filename으로 시작하는 모든 jpg파일(원본+증강) 찾기\n",
    "                matched_files = [f for f in os.listdir(img_folder) if f.startswith(base_filename) and f.endswith('.jpg')]\n",
    "                \n",
    "                for matched_file in matched_files:\n",
    "                    img_path = os.path.join(img_folder, matched_file)\n",
    "\n",
    "                    if not os.path.isfile(img_path):\n",
    "                        continue\n",
    "\n",
    "                    age = row.get('age')\n",
    "                    if age is not None and age >= 60:\n",
    "                        continue\n",
    "\n",
    "                    age_norm = (age - self.age_min) / (self.age_max - self.age_min) if age is not None else 0.0\n",
    "\n",
    "                    data = {\n",
    "                        'img_path': img_path,\n",
    "                        'category': category,\n",
    "                        'age': age_norm,\n",
    "                        'raw_age': age,\n",
    "                        'gender': row.get('gender'),\n",
    "                    }\n",
    "                    self.datalist.append(data)\n",
    "                \n",
    "    def __len__(self) :\n",
    "        return len(self.datalist)\n",
    "    \n",
    "    def __getitem__(self,idx) :\n",
    "        \n",
    "        data_item = self.datalist[idx]\n",
    "        image = Image.open(data_item['img_path']).convert('RGB')\n",
    "        \n",
    "        if self.transform is not None :\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        \n",
    "        \n",
    "        age=torch.tensor(data_item['age'], dtype=torch.float32)\n",
    "        gender = torch.tensor(1 if data_item['gender']=='남' else 0, dtype=torch.long)\n",
    "\n",
    "        return image, age, gender        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75f66950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sampling_weights(dataset):\n",
    "    weights = []\n",
    "    for sample in dataset.datalist:\n",
    "        age = sample.get('raw_age')\n",
    "        gender = sample.get('gender')\n",
    "\n",
    "        if age is None:\n",
    "            weights.append(1.0)\n",
    "            continue\n",
    "\n",
    "        age_group = (age // 10) * 10  # 10대, 20대, ...\n",
    "        if age_group == 10:\n",
    "            weight = 3.0 if gender == '남' else 1.3\n",
    "        elif age_group == 40:\n",
    "            weight = 1.1\n",
    "        elif age_group == 50:\n",
    "            weight = 2.0 if gender == '남' else 1.5\n",
    "        elif age_group ==20 :\n",
    "            weight = 1.4 if gender == '남' else 1.2\n",
    "        else:\n",
    "            weight = 1.0\n",
    "        weights.append(weight)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40b58970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456,0.406], #RGB평균\n",
    "                         [0.229,0.224,0.225])  #RGB 표준편차\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b89fe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categories=['anger','happy','panic','sadness']\n",
    "\n",
    "base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "train_image_dir = os.path.join(base_dir, 'augment')  # Final/augment\n",
    "train_label_dir = os.path.join(base_dir, 'CropData2', 'label', 'train')  # Final/CropData2/label/train\n",
    "\n",
    "val_image_dir = os.path.join(base_dir, 'CropData2', 'img', 'val')  # Final/CropData2/img/val\n",
    "val_label_dir = os.path.join(base_dir, 'CropData2', 'label', 'val')  # Final/CropData2/label/val\n",
    "\n",
    "train_data_load=DataProcessing(train_image_dir,train_label_dir,categories,transform=transform, mode='train')\n",
    "val_data_load = DataProcessing(val_image_dir, val_label_dir,categories, transform=transform, mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71384cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = get_sampling_weights(train_data_load)\n",
    "\n",
    "# 샘플러 정의\n",
    "sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a433dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_data_load,\n",
    "    batch_size=32,\n",
    "    sampler=sampler,\n",
    "    #num_workers=4,   # 2->4로 올려보기\n",
    "    #pin_memory=True  # GPU 사용 시 권장\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_data_load,\n",
    "    batch_size=32,\n",
    "    shuffle=False,     # 검증은 보통 셔플 안함\n",
    "    #num_workers=4,     # 워커 4개로 증가\n",
    "    #pin_memory=True    # GPU에 최적화\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c64c47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_e = models.resnet50(pretrained=False)\n",
    "\n",
    "model_e.fc = nn.Sequential(\n",
    "    nn.Linear(model_e.fc.in_features, 256),  # model_e.fc 인풋 피처 수 사용\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "\n",
    "    nn.Linear(256, 128),\n",
    "    nn.BatchNorm1d(128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "\n",
    "    nn.Linear(128, 64),\n",
    "    nn.BatchNorm1d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "\n",
    "    nn.Linear(64, 3)  # age(1), gender(2)\n",
    ")\n",
    "model_e = model_e.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7df519db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================================\n",
    "criterion_age = nn.MSELoss()\n",
    "criterion_gender = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_e.parameters(), lr=1e-4)\n",
    "num_epochs = 30 #수정가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f20cfd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device, criterion_age, criterion_gender) :\n",
    "    model.eval()\n",
    "    total_loss=0\n",
    "    accuracy = Accuracy(task='binary').to(device)\n",
    "    mae = MeanAbsoluteError().to(device) \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, ages, genders in data_loader :\n",
    "            images = images.to(device)\n",
    "            ages  = ages.to(device)\n",
    "            genders = genders.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            predicted_age = outputs[:,0]\n",
    "            predicted_gender_logits = outputs[:,1:3]\n",
    "            \n",
    "            loss_age = criterion_age(predicted_age, ages)\n",
    "            loss_gender = criterion_gender(predicted_gender_logits, genders)\n",
    "            loss = loss_age + loss_gender\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            pred = torch.argmax(predicted_gender_logits, dim=1)\n",
    "            accuracy.update(pred, genders)\n",
    "            mae.update(predicted_age, ages)\n",
    "    \n",
    "    avg_loss = total_loss / len(data_loader)        \n",
    "    return avg_loss, accuracy.compute(), mae.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67bcab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============모델 저장을 위한 빈 리스트 생성=============\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "train_maes = []\n",
    "val_maes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac190fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#================Early Stopping======================\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False):\n",
    "        self.patience = patience      # 개선 없을 때 참을 에폭 수\n",
    "        self.verbose = verbose        # 멈출 때 출력 여부\n",
    "        self.counter = 0              # 개선 없을 때 카운트\n",
    "        self.best_loss = np.Inf       # 최저 검증 손실 저장\n",
    "        self.early_stop = False       # 멈춤 여부\n",
    "        self.best_model_state = None  # 최적 모델 가중치 저장\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if val_loss < self.best_loss:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model_state = model.state_dict()\n",
    "            self.counter = 0\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss improved to {val_loss:.4f}. Saving model.')\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'No improvement for {self.counter} epochs.')\n",
    "            if self.counter >= self.patience:\n",
    "                if self.verbose:\n",
    "                    print('Early stopping triggered.')\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32c03acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30] - Training loss: 0.8503\n",
      "Epoch [2/30] - Training loss: 0.6599\n",
      "Epoch [3/30]\n",
      "Train Loss : 0.5097, Train Gender Accuracy : 0.7868, Train AGE MAE : 0.1788\n",
      "Validation Loss : 0.4358, Validation Gender Accuracy : 0.8095, Validation AGE MAE : 0.1307\n",
      "Validation loss improved to 0.4358. Saving model.\n",
      "Epoch [4/30] - Training loss: 0.4817\n",
      "Epoch [5/30] - Training loss: 0.4115\n",
      "Epoch [6/30]\n",
      "Train Loss : 0.4020, Train Gender Accuracy : 0.8369, Train AGE MAE : 0.1622\n",
      "Validation Loss : 0.3820, Validation Gender Accuracy : 0.8411, Validation AGE MAE : 0.1248\n",
      "Validation loss improved to 0.3820. Saving model.\n",
      "Epoch [7/30] - Training loss: 0.3219\n",
      "Epoch [8/30] - Training loss: 0.2726\n",
      "Epoch [9/30]\n",
      "Train Loss : 0.1640, Train Gender Accuracy : 0.9560, Train AGE MAE : 0.1511\n",
      "Validation Loss : 0.2001, Validation Gender Accuracy : 0.9351, Validation AGE MAE : 0.1176\n",
      "Validation loss improved to 0.2001. Saving model.\n",
      "Epoch [10/30] - Training loss: 0.1977\n",
      "Epoch [11/30] - Training loss: 0.1827\n",
      "Epoch [12/30]\n",
      "Train Loss : 0.1392, Train Gender Accuracy : 0.9624, Train AGE MAE : 0.1540\n",
      "Validation Loss : 0.2218, Validation Gender Accuracy : 0.9260, Validation AGE MAE : 0.1159\n",
      "No improvement for 1 epochs.\n",
      "Epoch [13/30] - Training loss: 0.1604\n",
      "Epoch [14/30] - Training loss: 0.1437\n",
      "Epoch [15/30]\n",
      "Train Loss : 0.0776, Train Gender Accuracy : 0.9850, Train AGE MAE : 0.1373\n",
      "Validation Loss : 0.1941, Validation Gender Accuracy : 0.9334, Validation AGE MAE : 0.1132\n",
      "Validation loss improved to 0.1941. Saving model.\n",
      "Epoch [16/30] - Training loss: 0.1115\n",
      "Epoch [17/30] - Training loss: 0.1082\n",
      "Epoch [18/30]\n",
      "Train Loss : 0.0634, Train Gender Accuracy : 0.9881, Train AGE MAE : 0.1311\n",
      "Validation Loss : 0.1923, Validation Gender Accuracy : 0.9401, Validation AGE MAE : 0.1138\n",
      "Validation loss improved to 0.1923. Saving model.\n",
      "Epoch [19/30] - Training loss: 0.0940\n",
      "Epoch [20/30] - Training loss: 0.0941\n",
      "Epoch [21/30]\n",
      "Train Loss : 0.0761, Train Gender Accuracy : 0.9828, Train AGE MAE : 0.1328\n",
      "Validation Loss : 0.2436, Validation Gender Accuracy : 0.9226, Validation AGE MAE : 0.1111\n",
      "No improvement for 1 epochs.\n",
      "Epoch [22/30] - Training loss: 0.0788\n",
      "Epoch [23/30] - Training loss: 0.0768\n",
      "Epoch [24/30]\n",
      "Train Loss : 0.0562, Train Gender Accuracy : 0.9896, Train AGE MAE : 0.1217\n",
      "Validation Loss : 0.1537, Validation Gender Accuracy : 0.9501, Validation AGE MAE : 0.1086\n",
      "Validation loss improved to 0.1537. Saving model.\n",
      "Epoch [25/30] - Training loss: 0.0612\n",
      "Epoch [26/30] - Training loss: 0.0726\n",
      "Epoch [27/30]\n",
      "Train Loss : 0.0485, Train Gender Accuracy : 0.9932, Train AGE MAE : 0.1269\n",
      "Validation Loss : 0.1786, Validation Gender Accuracy : 0.9493, Validation AGE MAE : 0.1105\n",
      "No improvement for 1 epochs.\n",
      "Epoch [28/30] - Training loss: 0.0597\n",
      "Epoch [29/30] - Training loss: 0.0572\n",
      "Epoch [30/30]\n",
      "Train Loss : 0.0337, Train Gender Accuracy : 0.9972, Train AGE MAE : 0.1131\n",
      "Validation Loss : 0.1557, Validation Gender Accuracy : 0.9493, Validation AGE MAE : 0.1074\n",
      "No improvement for 2 epochs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_e.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for images, ages, genders in train_loader:\n",
    "        images = images.to(device)\n",
    "        ages = ages.to(device)\n",
    "        genders = genders.to(device)\n",
    "\n",
    "        outputs = model_e(images)\n",
    "        predicted_age = outputs[:, 0]\n",
    "        predicted_gender_logits = outputs[:, 1:3]\n",
    "\n",
    "        loss_age = criterion_age(predicted_age, ages)\n",
    "        loss_gender = criterion_gender(predicted_gender_logits, genders)\n",
    "        loss = loss_age + loss_gender\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "\n",
    "    # 3 에폭마다 평가 및 기록 수행\n",
    "    if (epoch + 1) % 3 == 0 or epoch == num_epochs - 1:\n",
    "        train_loss, train_acc, train_mae = evaluate(model_e, train_loader, device, criterion_age, criterion_gender)\n",
    "        val_loss, val_acc, val_mae = evaluate(model_e, val_loader, device, criterion_age, criterion_gender)\n",
    "\n",
    "        val_losses.append(val_loss)\n",
    "        train_accuracies.append(train_acc.item())\n",
    "        val_accuracies.append(val_acc.item())\n",
    "        train_maes.append(train_mae.item())\n",
    "        val_maes.append(val_mae.item())\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "        print(f'Train Loss : {train_loss:.4f}, Train Gender Accuracy : {train_acc:.4f}, Train AGE MAE : {train_mae:.4f}')\n",
    "        print(f'Validation Loss : {val_loss:.4f}, Validation Gender Accuracy : {val_acc:.4f}, Validation AGE MAE : {val_mae:.4f}')\n",
    "\n",
    "        early_stopping(val_loss, model_e)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        # 평가 안 할 때는 학습 손실만 출력\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}] - Training loss: {avg_loss:.4f}')\n",
    "\n",
    "# 가장 좋은 가중치로 복원\n",
    "model_e.load_state_dict(early_stopping.best_model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4d39f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.dirname(os.paht.abspath(__file__))\n",
    "pth_save_path= os.path.join(base_dir,'pth_pkl','model_e_v1.pth')\n",
    "try:\n",
    "    torch.save(model_e.state_dict(), pth_save_path)\n",
    "    print(f'모델 저장 완료 → {pth_save_path}')\n",
    "except Exception as e:\n",
    "    print(f'모델 저장 실패: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3441bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\n",
    "    'train_losses': train_losses,\n",
    "    'val_losses': val_losses,\n",
    "    'train_accuracies': train_accuracies,\n",
    "    'val_accuracies': val_accuracies,\n",
    "    'train_maes': train_maes,\n",
    "    'val_maes': val_maes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea90afe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pkl\n",
    "base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "pkl_save_path = os.path.join(base_dir,'pth_pkl','model_e_v1.pkl')\n",
    "\n",
    "try:\n",
    "    with open(pkl_save_path, \"wb\") as f:\n",
    "        pickle.dump(history, f)\n",
    "    print(f'학습 기록이 성공적으로 저장되었습니다 : {pkl_save_path}')\n",
    "except Exception as e:\n",
    "    print(f'학습 기록 저장 실패: {e}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eunseo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
