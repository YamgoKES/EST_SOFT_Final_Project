{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f134e10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/cydonia999/VGGFace2-pytorch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5401ee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd VGGFace2-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcd7ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install facenet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894104df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import 부분\n",
    "\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "from functools import partial\n",
    "from models.resnet import resnet50\n",
    "from facenet_pytorch import MTCNN\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "#정확도 및 mae 임포트\n",
    "from torchmetrics import Accuracy, MeanAbsoluteError\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1198589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PyTorch 버전:\", torch.__version__)\n",
    "print(\"CUDA 사용 가능:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"현재 CUDA 디바이스 인덱스:\", torch.cuda.current_device())\n",
    "    print(\"CUDA 디바이스 이름:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA를 사용할 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f721bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805b1cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss는 그냥 비율 그대로 1:1 로 하고 진행할것 \n",
    "# MTCNN 전처리 + custom transform \n",
    "# augment_tranform 진행 ( 나이대별 성별별... )\n",
    "# 증강 수준은 그대로 진행도 될 듯함 gpu꼭 쓰게 하고... \n",
    "# WeightedRandomSampler적용 추가 버전임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eeaca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing class 만들기 파이프라인... 좀 정리하고 싶은데 일단 적읍시다\n",
    "\n",
    "class DataProcessing(Dataset) :\n",
    "    \n",
    "    #생성자 생성\n",
    "    def __init__(self, image_dir, label_dir, categories, transform=None, emotion_return=False,\n",
    "                 mode='train', augment_transform=None, mtcnn=None) :\n",
    "        \n",
    "        self.datalist = [] #이제 전체데이터 쓸거라 data로 변수명 바꿈\n",
    "        self.transform = transform\n",
    "        self.augment_transform = augment_transform\n",
    "        self.mtcnn = mtcnn\n",
    "        self.label_map = { cat :  idx for idx, cat in enumerate(categories)}\n",
    "        self.emotion_return = emotion_return\n",
    "        self.mode=mode\n",
    "        self.age_min = 10\n",
    "        self.age_max = 60\n",
    "        \n",
    "        for category in categories :\n",
    "            \n",
    "            json_path = os.path.join(label_dir, f'{self.mode}_{category}.json')\n",
    "            img_folder = os.path.join(image_dir, category)\n",
    "            \n",
    "            with open(json_path, 'r', encoding='euc-kr') as f :\n",
    "                label_data = json.load(f)\n",
    "            \n",
    "            for row in label_data :\n",
    "                \n",
    "                filename = row['filename']\n",
    "                img_path = os.path.join(img_folder, filename)\n",
    "                \n",
    "                if os.path.isfile(img_path) :\n",
    "                    \n",
    "                    age = row.get('age') \n",
    "                    \n",
    "                    #60대면 skip\n",
    "                    if age is not None and age >= 60 :\n",
    "                        continue \n",
    "                    \n",
    "                    #나이 정규화\n",
    "                    if age is not None : \n",
    "                        age_norm = (age - self.age_min) / (self.age_max - self.age_min) \n",
    "                    #결측값 (있지않지만 만약을 대비)\n",
    "                    else :\n",
    "                        age_norm = 0.0\n",
    "                        \n",
    "                    data = {\n",
    "                        'img_path' : img_path,\n",
    "                        'category' : category,\n",
    "                        'age' : age_norm,\n",
    "                        'raw_age' : age,\n",
    "                        'gender' : row.get('gender')\n",
    "                    }\n",
    "                    \n",
    "                    self.datalist.append(data)\n",
    "    \n",
    "    \n",
    "    def __len__(self) :\n",
    "        \n",
    "        return len(self.datalist)\n",
    "    \n",
    "    def __getitem__(self, idx) :\n",
    "        \n",
    "        data_item = self.datalist[idx]\n",
    "        image = Image.open(data_item['img_path']).convert('RGB')\n",
    "        \n",
    "        if self.mtcnn is not None :\n",
    "            \n",
    "            face_img = self.mtcnn(image)\n",
    "            \n",
    "            if face_img is None :\n",
    "                image = image.resize((224,224))\n",
    "                face_img = transforms.ToTensor()(image)\n",
    "                \n",
    "        else :\n",
    "            \n",
    "            face_img = transforms.ToTensor()(image)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        age_norm = data_item['age']\n",
    "        \n",
    "        augment_flag = False\n",
    "        if (0 <= age_norm <= 0.18) or (0.6 <= age_norm <= 0.78) or (0.8 <= age_norm <= 0.98):\n",
    "            augment_flag = True\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            if augment_flag and self.augment_transform is not None:\n",
    "                face_img = self.augment_transform(face_img)\n",
    "            elif self.transform is not None:\n",
    "                face_img = self.transform(face_img)\n",
    "        else:\n",
    "            if self.transform is not None:\n",
    "                face_img = self.transform(face_img)\n",
    "\n",
    "        \n",
    "        #emotion_label = torch.tensor(self.label_map[sample['category']], dtype=torch.long) 수정1\n",
    "        age=torch.tensor(data_item['age'], dtype=torch.float32)\n",
    "        gender = torch.tensor(1 if data_item['gender']=='남' else 0, dtype=torch.long)\n",
    "\n",
    "        # return image, emotion_label, age, gender 수정1\n",
    "\n",
    "        if self.emotion_return :\n",
    "            emotion_label = torch.tensor(self.label_map[data_item['category']], dtype=torch.long)\n",
    "            return face_img, emotion_label, age, gender\n",
    "\n",
    "        else :\n",
    "            return face_img, age, gender\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da00fac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sampling_weights(dataset):\n",
    "    \"\"\"\n",
    "    데이터셋 내 각 샘플에 대해 클래스 불균형을 보정하는 가중치 부여\n",
    "    - 10대 남: 3.0\n",
    "    - 10대 여: 2.0\n",
    "    - 40대: 1.5\n",
    "    - 50대 남: 2.0\n",
    "    - 50대 여: 1.5\n",
    "    - 그 외: 1.0 (20대 30대)\n",
    "    \"\"\"\n",
    "    weights = []\n",
    "    for sample in dataset.datalist:\n",
    "        age = sample.get('raw_age')\n",
    "        gender = sample.get('gender')\n",
    "\n",
    "        if age is None:\n",
    "            weights.append(1.0)\n",
    "            continue\n",
    "\n",
    "        age_group = (age // 10) * 10  # 10대, 20대, ...\n",
    "        if age_group == 10:\n",
    "            weight = 3.0 if gender == '남' else 2.0\n",
    "        elif age_group == 40:\n",
    "            weight = 1.5\n",
    "        elif age_group == 50:\n",
    "            weight = 2.0 if gender == '남' else 1.5\n",
    "        else:\n",
    "            weight = 1.0\n",
    "        weights.append(weight)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b127b897",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(image_size=224, margin=20, min_face_size=20,thresholds=[0.6, 0.7, 0.7], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14f4c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform\n",
    "transform = transforms.Compose([\n",
    "    #transforms.Resize((224,224)), #이미지 사이즈 조정\n",
    "    transforms.Normalize([0.485, 0.456,0.406], #RGB평균\n",
    "                         [0.229,0.224,0.225])  #RGB 표준편차\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e91c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32c2ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categories=['anger','happy','panic','sadness']\n",
    "\n",
    "base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "train_image_dir = os.path.join(base_dir,'Data','img', 'train')\n",
    "train_label_dir = os.path.join(base_dir,'Data','label', 'train')\n",
    "val_image_dir = os.path.join(base_dir,'Data','img', 'val')\n",
    "val_label_dir = os.path.join(base_dir,'Data','label', 'val')\n",
    "\n",
    "train_data_load=DataProcessing(train_image_dir,train_label_dir,categories,transform=transform,augment_transform=augment_transform, mode='train',mtcnn=mtcnn )\n",
    "val_data_load = DataProcessing(val_image_dir, val_label_dir,categories, transform=transform, mode='val',mtcnn=mtcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ccb944",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = get_sampling_weights(train_data_load)\n",
    "\n",
    "# 샘플러 정의\n",
    "sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faafbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_data_load,\n",
    "    batch_size=32,\n",
    "    sampler=sampler,\n",
    "    num_workers=2  # 시스템에 따라 조절\n",
    ")\n",
    "val_loader= DataLoader(val_data_load, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e5caf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================모델 가져오기 2번째 custum v1.2 ==============\n",
    "model_v2_2_1_4 = resnet50()\n",
    "\n",
    "model_v2_2_1_4.fc = nn.Sequential(\n",
    "    nn.Linear(model_v2_2_1_4.fc.in_features,256),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    \n",
    "    nn.Linear(256,128),\n",
    "    nn.BatchNorm1d(128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    \n",
    "    nn.Linear(128,64),\n",
    "    nn.BatchNorm1d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    \n",
    "    nn.Linear(64,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe05544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#================ 3.가중치 불러오기 ===============\n",
    "base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "weight_path = os.path.join(base_dir, 'resnet50_ft_weight.pkl')\n",
    "\n",
    "with open(weight_path, 'rb') as f:\n",
    "    state_dict = pickle.load(f)\n",
    "    \n",
    "\n",
    "for key in state_dict:\n",
    "    if isinstance(state_dict[key], np.ndarray):\n",
    "        state_dict[key] = torch.from_numpy(state_dict[key])\n",
    "\n",
    "model_v2_2_1_4.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "\n",
    "# 5. 디바이스에 올리기\n",
    "model_v2_2_1_4 = model_v2_2_1_4.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f55703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================================\n",
    "criterion_age = nn.MSELoss()\n",
    "criterion_gender = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_v2_2_1_4.parameters(), lr=1e-4)\n",
    "num_epochs = 10 #수정가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdda5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device, criterion_age, criterion_gender) :\n",
    "    model.eval()\n",
    "    total_loss=0\n",
    "    accuracy = Accuracy(task='binary').to(device)\n",
    "    mae = MeanAbsoluteError().to(device) \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, ages, genders in data_loader :\n",
    "            images = images.to(device)\n",
    "            ages  = ages.to(device)\n",
    "            genders = genders.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            predicted_age = outputs[:,0]\n",
    "            predicted_gender_logits = outputs[:,1:3]\n",
    "            \n",
    "            loss_age = criterion_age(predicted_age, ages)\n",
    "            loss_gender = criterion_gender(predicted_gender_logits, genders)\n",
    "            loss = loss_age + loss_gender\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            pred = torch.argmax(predicted_gender_logits, dim=1)\n",
    "            accuracy.update(pred, genders)\n",
    "            mae.update(predicted_age, ages)\n",
    "    \n",
    "    avg_loss = total_loss / len(data_loader)        \n",
    "    return avg_loss, accuracy.compute(), mae.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ab0578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============모델 저장을 위한 빈 리스트 생성=============\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "train_maes = []\n",
    "val_maes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d7c361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#================Early Stopping======================\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False):\n",
    "        self.patience = patience      # 개선 없을 때 참을 에폭 수\n",
    "        self.verbose = verbose        # 멈출 때 출력 여부\n",
    "        self.counter = 0              # 개선 없을 때 카운트\n",
    "        self.best_loss = np.Inf       # 최저 검증 손실 저장\n",
    "        self.early_stop = False       # 멈춤 여부\n",
    "        self.best_model_state = None  # 최적 모델 가중치 저장\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if val_loss < self.best_loss:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model_state = model.state_dict()\n",
    "            self.counter = 0\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss improved to {val_loss:.4f}. Saving model.')\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'No improvement for {self.counter} epochs.')\n",
    "            if self.counter >= self.patience:\n",
    "                if self.verbose:\n",
    "                    print('Early stopping triggered.')\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af3361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================== 학습 ===========================\n",
    "early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_v2_2_1_4.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for images, ages, genders in train_loader:\n",
    "        \n",
    "        images = images.to(device)\n",
    "        ages = ages.to(device)\n",
    "        genders = genders.to(device)\n",
    "\n",
    "        outputs = model_v2_2_1_4(images)\n",
    "        predicted_age = outputs[:, 0]\n",
    "        predicted_gender_logits = outputs[:, 1:3]\n",
    "\n",
    "        loss_age = criterion_age(predicted_age, ages)\n",
    "        loss_gender = criterion_gender(predicted_gender_logits, genders)\n",
    "        loss = loss_age + loss_gender\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    #avg_loss = epoch_loss / len(train_loader)\n",
    "\n",
    "    # === 평가 ===\n",
    "    train_loss, train_acc, train_mae = evaluate(model_v2_2_1_4, train_loader, device, criterion_age, criterion_gender)\n",
    "    val_loss, val_acc, val_mae = evaluate(model_v2_2_1_4, val_loader, device, criterion_age, criterion_gender)\n",
    "\n",
    "    # === 저장 ===\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accuracies.append(train_acc.item())\n",
    "    val_accuracies.append(val_acc.item())\n",
    "    train_maes.append(train_mae.item())\n",
    "    val_maes.append(val_mae.item())\n",
    "\n",
    "    # ==== 출력 =====\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "    print(f'Train Loss : {train_loss : .4f}, Train Gender Accuracy : {train_acc : .4f}, Train AGE MAE : {train_mae : .4f}')\n",
    "    print(f'Validation Loss : {val_loss : .4f}, Validation Gender Accuracy : {val_acc : .4f}, Validation AGE MAE : {val_mae : .4f}')\n",
    "    \n",
    "    early_stopping(val_loss, model_v2_2_1_4)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "# 가장 좋은 가중치로 복원\n",
    "model_v2_2_1_4.load_state_dict(early_stopping.best_model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cab7519",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "pth_save_path = os.path.join(base_dir, 'pth_pkl', 'model_raw_weights_v2_2_1_4.pth')\n",
    "\n",
    "try:\n",
    "    torch.save(model_v2_2_1_4.state_dict(), pth_save_path)\n",
    "    print(f'모델 저장 완료 → {pth_save_path}')\n",
    "except Exception as e:\n",
    "    print(f'모델 저장 실패: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9497faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\n",
    "    'train_losses': train_losses,\n",
    "    'val_losses': val_losses,\n",
    "    'train_accuracies': train_accuracies,\n",
    "    'val_accuracies': val_accuracies,\n",
    "    'train_maes': train_maes,\n",
    "    'val_maes': val_maes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c352320",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "pkl_save_path = os.path.join(base_dir, 'pth_pkl', 'model_raw_v2_2_1_4.pkl')\n",
    "\n",
    "try:\n",
    "    with open(pkl_save_path, \"wb\") as f:\n",
    "        pickle.dump(history, f)\n",
    "    print(f'학습 기록이 성공적으로 저장되었습니다 : {pkl_save_path}')\n",
    "except Exception as e:\n",
    "    print(f'학습 기록 저장 실패: {e}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eunseo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
