{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95b171e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b0686de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 설정\n",
    "DATA_DIR = '/workspace/data/Data_unzipped'\n",
    "TRAIN_IMG_PATH = os.path.join(DATA_DIR, 'img', 'train')\n",
    "VALID_IMG_PATH = os.path.join(DATA_DIR, 'img', 'val')\n",
    "TRAIN_LABEL_PATH = os.path.join(DATA_DIR, 'label', 'train')\n",
    "VALID_LABEL_PATH = os.path.join(DATA_DIR, 'label', 'val')\n",
    "\n",
    "TEST_DIR = '/workspace/data/test_unzipped'\n",
    "TEST_IMG_PATH = os.path.join(TEST_DIR, 'image')\n",
    "TEST_LABEL_PATH = os.path.join(TEST_DIR, 'label')\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "SAVE_DIR = '/workspace/yonghak'\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8306a15b",
   "metadata": {},
   "source": [
    "##### emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79257214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감정 저장\n",
    "def load_labels(label_path, dataset_type=''):\n",
    "    if dataset_type:\n",
    "        label_path = os.path.join(label_path, dataset_type)\n",
    "    labels = {}\n",
    "    for file_name in os.listdir(label_path):\n",
    "        if file_name.endswith('.json'):\n",
    "            with open(os.path.join(label_path, file_name), 'r', encoding='euc-kr') as f:\n",
    "                data = json.load(f)\n",
    "                for item in data:\n",
    "                    filename = item['filename']\n",
    "                    face_exp = item['faceExp_uploader']\n",
    "                    labels[filename] = face_exp\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adef5402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_and_save_all_dataset(\n",
    "    train_img_dir, train_labels,\n",
    "    val_img_dir, val_labels,\n",
    "    test_img_dir, test_labels,\n",
    "    img_size, save_path\n",
    "):\n",
    "    all_images = []\n",
    "    all_emotions = []\n",
    "    all_sets = []\n",
    "\n",
    "    def add_images(img_dir, labels, set_name):\n",
    "        for root, _, files in os.walk(img_dir):\n",
    "            for file in files:\n",
    "                if file in labels:\n",
    "                    img_path = os.path.join(root, file)\n",
    "                    image = Image.open(img_path).convert('RGB')\n",
    "                    image = image.resize(img_size)\n",
    "                    all_images.append(np.array(image))\n",
    "                    all_emotions.append(labels[file])\n",
    "                    all_sets.append(set_name)\n",
    "\n",
    "    add_images(train_img_dir, train_labels, 'train')\n",
    "    add_images(val_img_dir, val_labels, 'val')\n",
    "    add_images(test_img_dir, test_labels, 'test')\n",
    "\n",
    "    all_images = np.array(all_images)\n",
    "    all_emotions = np.array(all_emotions)\n",
    "    all_sets = np.array(all_sets)\n",
    "    np.savez(save_path, images=all_images, emotions=all_emotions, sets=all_sets)\n",
    "    print(f\"{save_path} 저장 완료 (총 {all_images.shape[0]}장)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1d1bc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/yonghak/image_emotion_dataset.npz 저장 완료 (총 8394장)\n"
     ]
    }
   ],
   "source": [
    "# 실행\n",
    "save_path_emotion = os.path.join(SAVE_DIR, 'image_emotion_dataset.npz')\n",
    "train_labels = load_labels(TRAIN_LABEL_PATH)\n",
    "val_labels = load_labels(VALID_LABEL_PATH)\n",
    "test_labels = load_labels(TEST_LABEL_PATH)\n",
    "\n",
    "prepare_and_save_all_dataset(\n",
    "    TRAIN_IMG_PATH, train_labels,\n",
    "    VALID_IMG_PATH, val_labels,\n",
    "    TEST_IMG_PATH, test_labels,\n",
    "    IMG_SIZE, save_path_emotion\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2aee7cf",
   "metadata": {},
   "source": [
    "##### emotion, bounding box crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59e341e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bounding box crop + 감정 저장\n",
    "def load_labels_and_boxes(label_path):\n",
    "    labels = {}\n",
    "    boxes = {}\n",
    "    for file_name in os.listdir(label_path):\n",
    "        if file_name.endswith('.json'):\n",
    "            with open(os.path.join(label_path, file_name), 'r', encoding='euc-kr') as f:\n",
    "                data = json.load(f)\n",
    "                for item in data:\n",
    "                    filename = item['filename']\n",
    "                    face_exp = item['faceExp_uploader']\n",
    "                    box_info = item['annot_A']['boxes']\n",
    "                    bbox = [box_info['minX'], box_info['minY'], box_info['maxX'], box_info['maxY']]\n",
    "                    labels[filename] = face_exp\n",
    "                    boxes[filename] = bbox\n",
    "    return labels, boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31817236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_and_save_all_dataset_with_crop(\n",
    "    train_img_dir, train_labels, train_boxes,\n",
    "    val_img_dir, val_labels, val_boxes,\n",
    "    test_img_dir, test_labels, test_boxes,\n",
    "    img_size, save_path\n",
    "):\n",
    "    all_images = []\n",
    "    all_emotions = []\n",
    "    all_sets = []\n",
    "\n",
    "    def add_images(img_dir, labels, boxes, set_name):\n",
    "        for root, _, files in os.walk(img_dir):\n",
    "            for file in files:\n",
    "                if file in labels and file in boxes:\n",
    "                    img_path = os.path.join(root, file)\n",
    "                    image = Image.open(img_path).convert('RGB')\n",
    "                    minX, minY, maxX, maxY = [int(round(x)) for x in boxes[file]]\n",
    "                    face_img = image.crop((minX, minY, maxX, maxY))\n",
    "                    face_img = face_img.resize(img_size)\n",
    "                    all_images.append(np.array(face_img))\n",
    "                    all_emotions.append(labels[file])\n",
    "                    all_sets.append(set_name)\n",
    "\n",
    "    add_images(train_img_dir, train_labels, train_boxes, 'train')\n",
    "    add_images(val_img_dir, val_labels, val_boxes, 'val')\n",
    "    add_images(test_img_dir, test_labels, test_boxes, 'test')\n",
    "\n",
    "    all_images = np.array(all_images)\n",
    "    all_emotions = np.array(all_emotions)\n",
    "    all_sets = np.array(all_sets)\n",
    "    np.savez(save_path, images=all_images, emotions=all_emotions, sets=all_sets)\n",
    "    print(f\"{save_path} 저장 완료 (총 {all_images.shape[0]}장)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e11c761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/yonghak/image_emotion_crop_dataset.npz 저장 완료 (총 8394장)\n"
     ]
    }
   ],
   "source": [
    "# 실행\n",
    "save_path_crop = os.path.join(SAVE_DIR, 'image_emotion_crop_dataset.npz')\n",
    "train_labels, train_boxes = load_labels_and_boxes(TRAIN_LABEL_PATH)\n",
    "val_labels, val_boxes = load_labels_and_boxes(VALID_LABEL_PATH)\n",
    "test_labels, test_boxes = load_labels_and_boxes(TEST_LABEL_PATH)\n",
    "\n",
    "prepare_and_save_all_dataset_with_crop(\n",
    "    TRAIN_IMG_PATH, train_labels, train_boxes,\n",
    "    VALID_IMG_PATH, val_labels, val_boxes,\n",
    "    TEST_IMG_PATH, test_labels, test_boxes,\n",
    "    IMG_SIZE, save_path_crop\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8de0223",
   "metadata": {},
   "source": [
    "##### AffectNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd4361ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사전학습에 사용할 이미지 수: 11207\n",
      "Saved full pretrain dataset to /workspace/yonghak/vit2_pretrain_emotion_full_dataset.npz\n",
      " images shape      : (11207, 224, 224, 3)\n",
      " labels shape      : (11207,)\n",
      " class_weights     : [2.9330018 3.7734008 4.6618137 5.5700793]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "\n",
    "# 경로 설정\n",
    "pretrain_dir = '/workspace/data/AffectNet_unzipped/affectnet_cleaned'\n",
    "csv_path = os.path.join(pretrain_dir, 'labels_filtered_cleaned.csv')\n",
    "save_path = '/workspace/yonghak/vit2_pretrain_emotion_full_dataset.npz'\n",
    "\n",
    "# CSV에서 라벨 매핑 정보 읽기\n",
    "df = pd.read_csv(csv_path)\n",
    "# 문자열 감정 → 정수 인덱스 매핑\n",
    "mapping = {'happy':0, 'surprise':1, 'anger':2, 'sad':3}\n",
    "# 상대경로(pth) → 정수 라벨\n",
    "label_map = {row['pth']: mapping[row['label']] for _, row in df.iterrows()}\n",
    "\n",
    "# 디스크에 실제 존재하는 경로만 교집합으로 걸러내기\n",
    "disk_paths = {\n",
    "    os.path.relpath(os.path.join(r, f), pretrain_dir)\n",
    "    for r, _, fs in os.walk(pretrain_dir) for f in fs\n",
    "}\n",
    "valid_paths = sorted(set(label_map.keys()) & disk_paths)\n",
    "print(f\"사전학습에 사용할 이미지 수: {len(valid_paths)}\")\n",
    "\n",
    "# 이미지 배열과 라벨 배열로 메모리에 로드\n",
    "images = []\n",
    "labels = []\n",
    "for rel in valid_paths:\n",
    "    img_path = os.path.join(pretrain_dir, rel)\n",
    "    img = Image.open(img_path).convert('RGB').resize((224,224))\n",
    "    images.append(np.array(img))\n",
    "    labels.append(label_map[rel])\n",
    "images = np.stack(images)    # shape: (N, 224, 224, 3)\n",
    "labels = np.array(labels)    # shape: (N,)\n",
    "\n",
    "# 클래스 분포 기반 가중치 계산\n",
    "counts = Counter(labels)\n",
    "total  = sum(counts.values())\n",
    "num_classes = len(mapping)\n",
    "class_weights = np.array(\n",
    "    [ total / counts[i] for i in range(num_classes) ],\n",
    "    dtype=np.float32\n",
    ")\n",
    "\n",
    "# NPZ 파일로 저장\n",
    "np.savez(\n",
    "    save_path,\n",
    "    images=images,\n",
    "    labels=labels,\n",
    "    class_weights=class_weights\n",
    ")\n",
    "print(f\"Saved full pretrain dataset to {save_path}\")\n",
    "print(f\" images shape      : {images.shape}\")\n",
    "print(f\" labels shape      : {labels.shape}\")\n",
    "print(f\" class_weights     : {class_weights}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
